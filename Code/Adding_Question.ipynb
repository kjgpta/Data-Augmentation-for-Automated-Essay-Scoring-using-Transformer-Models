{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2h3FOb27KqX4"
      },
      "source": [
        "#Adding Question to the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6vNUIaLQztE"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9opGIid0kBui"
      },
      "outputs": [],
      "source": [
        "with open('questions.pkl', 'rb') as f:\n",
        "    questions = pkl.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDCvD39Kgdh"
      },
      "source": [
        "## Topicwise addition for each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1M2Zo0nnAOh"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "for i in range(1,9):\n",
        "    df = pd.DataFrame(columns = column)\n",
        "    filename = \"Training_Data/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"final_score\"]\n",
        "        sentences = essay.split(\".\")\n",
        "        ar = []\n",
        "        for index in range(len(sentences)):\n",
        "            if index%5 == 0:\n",
        "                ar.append(questions[i-1])\n",
        "            ar.append(sentences[index])\n",
        "        string = \". \".join(s for s in ar)\n",
        "        df.loc[len(df.index)] = [string, score]\n",
        "    filetosave = \"Training_Data_with_questions/data\"+str(i)+\".csv\"\n",
        "    df.to_csv(filetosave, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K9tQdJQoEN4"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "for i in range(1,9):\n",
        "    df = pd.DataFrame(columns = column)\n",
        "    filename = \"Validation_Data/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"final_score\"]\n",
        "        sentences = essay.split(\".\")\n",
        "        ar = []\n",
        "        for index in range(len(sentences)):\n",
        "            if index%10 == 0:\n",
        "                ar.append(questions[i-1])\n",
        "            ar.append(sentences[index])\n",
        "        string = \". \".join(s for s in ar)\n",
        "        df.loc[len(df.index)] = [string, score]\n",
        "    filetosave = \"Validation_Data_with_questions/data\"+str(i)+\".csv\"\n",
        "    df.to_csv(filetosave, index = False)\n",
        "    print(i)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wivMZ3E6Ky4U"
      },
      "source": [
        "## Topicwise Addition to the complete set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PkVKuZa-NxE"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "df = pd.DataFrame(columns = column)\n",
        "for i in range(1,9):\n",
        "    filename = \"Training_Data/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"final_score\"]\n",
        "        sentences = essay.split(\".\")\n",
        "        ar = []\n",
        "        for index in range(len(sentences)):\n",
        "            if index%10 == 0:\n",
        "                ar.append(questions[i-1])\n",
        "            ar.append(sentences[index])\n",
        "        string = \". \".join(s for s in ar)\n",
        "        df.loc[len(df.index)] = [string, score]\n",
        "\n",
        "filetosave = \"Training_data.csv\"\n",
        "df.to_csv(filetosave, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhz_Zs1GDpAl"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "df2 = pd.DataFrame(columns = column)\n",
        "for i in range(1,9):\n",
        "    filename = \"Validation_Data/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"final_score\"]\n",
        "        sentences = essay.split(\".\")\n",
        "        ar = []\n",
        "        for index in range(len(sentences)):\n",
        "            if index%10 == 0:\n",
        "                ar.append(questions[i-1])\n",
        "            ar.append(sentences[index])\n",
        "        string = \". \".join(s for s in ar)\n",
        "        df2.loc[len(df2.index)] = [string, score]\n",
        "\n",
        "filetosave = \"Validation_data.csv\"\n",
        "df2.to_csv(filetosave, index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

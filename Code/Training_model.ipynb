{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_EsU8LLQya4"
      },
      "outputs": [],
      "source": [
        "!pip install -q simpletransformers \n",
        "!pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6vNUIaLQztE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import sklearn\n",
        "import os\n",
        "import torch\n",
        "import pickle as pkl\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing the Data by removing Stopwords"
      ],
      "metadata": {
        "id": "x30t6axrP9oi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUuI3gfg53Dq"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "for i in range(1,9):\n",
        "    filename = \"Training_Data_with_questions/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    df = pd.DataFrame(columns = column)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"score\"]\n",
        "        string = remove_stopwords(essay)\n",
        "        df.loc[len(df.index)] = [string, score]\n",
        "    df.to_excel(\"Training_Data_stopwords/data\"+str(i)+\".xlsx\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyQwxLic8jmf"
      },
      "outputs": [],
      "source": [
        "column = [\"essay\", \"score\"]\n",
        "for i in range(1,9):\n",
        "    filename = \"Validation_Data_with_questions/data\"+str(i)+\".csv\"\n",
        "    train_csv = pd.read_csv(filename)\n",
        "    df = pd.DataFrame(columns = column)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"score\"]\n",
        "        string = remove_stopwords(essay)\n",
        "        df.loc[len(df.index)] = [string, score]\n",
        "    df.to_excel(\"Validation_Data_stopwords/data\"+str(i)+\".xlsx\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column = [\"Essay ID\", \"essay\", \"score\"]\n",
        "df = pd.DataFrame(columns = column)\n",
        "for i in range(1,9):\n",
        "    filename = \"Training_Data_stopwords/data\"+str(i)+\".xlsx\"\n",
        "    train_csv = pd.read_excel(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"score\"]\n",
        "        df.loc[len(df.index)] = [i, essay, score]\n",
        "df.to_excel(\"combined_data_train.xlsx\", index = False)"
      ],
      "metadata": {
        "id": "6jUWWZH7gLSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column = [\"Essay ID\", \"essay\", \"score\"]\n",
        "df = pd.DataFrame(columns = column)\n",
        "for i in range(1,9):\n",
        "    filename = \"Validation_Data_stopwords/data\"+str(i)+\".xlsx\"\n",
        "    train_csv = pd.read_excel(filename)\n",
        "    for j in range(len(train_csv)):\n",
        "        essay = train_csv.at[j,\"essay\"]\n",
        "        score = train_csv.at[j, \"score\"]\n",
        "        df.loc[len(df.index)] = [i, essay, score]\n",
        "df.to_excel(\"combined_data_val.xlsx\", index = False)"
      ],
      "metadata": {
        "id": "dU3gnhI8qG_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Training and Validation Data"
      ],
      "metadata": {
        "id": "31IfXK4lQDvG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5sdBPFpq7V5"
      },
      "outputs": [],
      "source": [
        "def prepare_data(tr_file, vl_file):\n",
        "    # Preparing train data\n",
        "    train_data = []\n",
        "    tr_data = pd.read_excel(tr_file)\n",
        "    for i in range(len(tr_data)):\n",
        "        train_data.append([tr_data.at[i,\"essay\"], tr_data.at[i,\"score\"]])\n",
        "    random.shuffle(train_data)\n",
        "    final_train_data = [ele for ele in train_data if ele != []]\n",
        "\n",
        "    # Preparing eval data\n",
        "    val_data = []\n",
        "    vl_data = pd.read_excel(vl_file)\n",
        "    for i in range(len(vl_data)):\n",
        "        val_data.append([vl_data.at[i,\"essay\"], vl_data.at[i,\"score\"]])\n",
        "    random.shuffle(val_data)\n",
        "    final_val_data = [ele for ele in val_data if ele != []]\n",
        "\n",
        "    return final_train_data, final_val_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_file = \"combined_data_train.xlsx\"\n",
        "vl_file = \"combined_data_val.xlsx\"\n",
        "final_train_data, final_val_data = prepare_data(tr_file, vl_file)\n",
        "print(\"Data Prepared\")"
      ],
      "metadata": {
        "id": "9v4uFpCkq_k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_eoJaAs9G_"
      },
      "outputs": [],
      "source": [
        "def train_data(final_train_data, final_val_data, filetosave, model_name, wd, lr):\n",
        "\n",
        "    train_df = pd.DataFrame(final_train_data)\n",
        "    train_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "    eval_df = pd.DataFrame(final_val_data)\n",
        "    eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    transformers_logger = logging.getLogger(\"transformers\")\n",
        "    transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "    model_args = ClassificationArgs()\n",
        "    model_args.num_train_epochs = 15\n",
        "    model_args.regression = False\n",
        "    model_args.overwrite_output_dir = True\n",
        "    model_args.train_batch_size= 32\n",
        "    model_args.save_model_every_epoch=False\n",
        "    model_args.weight_decay = wd\n",
        "    model_args.learning_rate = lr\n",
        "    # Create a ClassificationModel\n",
        "    if model_name == \"roberta\":\n",
        "        model = ClassificationModel(\n",
        "            \"roberta\",\n",
        "            \"roberta-base\",\n",
        "            num_labels=11,\n",
        "            args=model_args,\n",
        "            use_cuda = True,\n",
        "            cuda_device = 0,\n",
        "        )\n",
        "    elif model_name == \"xlm-roberta\":\n",
        "        model = ClassificationModel(\n",
        "            \"xlmroberta\",\n",
        "            \"xlm-roberta-base\",\n",
        "            num_labels=11,\n",
        "            args=model_args,\n",
        "            use_cuda = True,\n",
        "            cuda_device = 0,\n",
        "        )\n",
        "    elif model_name == \"bert\":\n",
        "        model = ClassificationModel(\n",
        "            \"bert\",\n",
        "            \"bert-base-uncased\",\n",
        "            num_labels=11,\n",
        "            args=model_args,\n",
        "            use_cuda = True,\n",
        "            cuda_device = 0,\n",
        "        )\n",
        "    elif model_name == \"albert\":\n",
        "        model = ClassificationModel(\n",
        "            \"albert\",\n",
        "            \"albert-base-v2\",\n",
        "            num_labels=11,\n",
        "            args=model_args,\n",
        "            use_cuda = True,\n",
        "            cuda_device = 0,\n",
        "        )\n",
        "    elif model_name == \"distilbert\":\n",
        "        model = ClassificationModel(\n",
        "            \"distilbert\",\n",
        "            \"distilbert-base-uncased\",\n",
        "            num_labels=11,\n",
        "            args=model_args,\n",
        "            use_cuda = True,\n",
        "            cuda_device = 0,\n",
        "        )\n",
        "\n",
        "    # Train the model\n",
        "    model.train_model(train_df)\n",
        "\n",
        "    # Evaluate the model\n",
        "    result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "\n",
        "    filetosave = filetosave + \"_\" + model_name + \"_lr =\" + str(lr) + \" _wd =\"+ str(wd)+\".pkl\"\n",
        "    \n",
        "    pkl.dump(model, open(filetosave, 'wb'))\n",
        "    \n",
        "    return filetosave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_data(final_train_data, final_val_data, filetoopen, df, datafile, weight_decay, learning_rate):\n",
        "    datafile = datafile.upper()\n",
        "    with open(filetoopen, 'rb') as f:\n",
        "        model = pkl.load(f)\n",
        "    \n",
        "    evaluation_text = [text for text, _ in final_val_data]\n",
        "    evaluation_label = [label for _, label in final_val_data]\n",
        "    pred_on_evaluation_set, _ = model.predict(evaluation_text)\n",
        "\n",
        "    print(\"Evaluation Data Results:\")\n",
        "    acc = accuracy_score(pred_on_evaluation_set, evaluation_label)\n",
        "    print(\"Accuracy = \", acc)\n",
        "    df.loc[len(df.index)] = [\"Evaluation: \" + str(datafile), acc, cks]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "wjYgVGFnrzQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_Train(model_name, df, weight_decay, learning_rate, final_train_data, final_val_data):\n",
        "        filetoopen = train_data(final_train_data, final_val_data, filetosave, model_name, weight_decay, learning_rate)\n",
        "        df = evaluate_data(final_train_data, final_val_data, filetoopen, df, model_name, weight_decay, learning_rate)\n",
        "        df.loc[len(df.index)] = [\"---------------\", \"---------------\", \"---------------\"]\n",
        "        return df"
      ],
      "metadata": {
        "id": "K4SCKDETqqPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = [\"Model\", \"Accuracy\", \"Cohen Kappa Score\"]\n",
        "df = read_excel(\"Results.xlsx\")\n",
        "weight_decay = 5e-4\n",
        "learning_rate = 1e-4\n",
        "ar = [\"roberta\", \"xlm-roberta\", \"bert\", \"albert\", \"distilbert\"]\n",
        "for i in ar:\n",
        "    df = model_Train(i, df, weight_decay, learning_rate, final_train_data, final_val_data)\n",
        "df.to_excel(\"Results.xlsx\" , index = False)"
      ],
      "metadata": {
        "id": "ZutUoSyYXvRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results Generated!!!\")"
      ],
      "metadata": {
        "id": "O5xD-RI0Pef_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}